My commit is 84e8fb45 Write heterogeneous profile results to file (/root/dev/models/deploy)

==========================================================================
My environment variables:
--------------------------------------------------------------------------
CUDNN_VERSION=7.6.2.24-1+cuda10.1
PMIX_ID=3722510337.0
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
LD_LIBRARY_PATH=/usr/local/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
OMPI_FIRST_RANKS=0
MPI_HOSTS=e885f9af0739,dd6eaccac059
OMPI_MCA_orte_top_session_dir=/tmp/ompi.dd6eaccac059.0
LOG_MEMORY_ENABLED=false
PMIX_SYSTEM_TMPDIR=/tmp
OMPI_MCA_orte_num_nodes=1
OMPI_COMMAND=run_resnet.sh
MODEL=resnet
LANG=C.UTF-8
HFI_NO_BACKTRACE=1
HOSTNAME=dd6eaccac059
OMPI_MCA_ess_base_vpid=0
OLDPWD=/root/dev/train_data
OMPI_MCA_initial_wdir=/root/dev/models/deploy
ENVIRONMENT=docker
TF_DIR=/root/dev/tensorflow
DATA_DIR=/root/dev/dataset/cifar10/cifar-10-batches-bin
HOST_FLAG=--host e885f9af0739,dd6eaccac059
OMPI_MCA_btl_tcp_if_exclude=lo,docker0,eth1
DATASET=cifar10
DTYPE=fp16
NUM_CHECKPOINTS_TO_KEEP=5
OMPI_COMM_WORLD_NODE_RANK=0
NVIDIA_VISIBLE_DEVICES=all
OMPI_MCA_orte_precondition_transports=2f47d4f419f39ccc-5654f63b5e4bb302
BASE_DIR=/root/dev
OMPI_MCA_orte_ess_node_rank=0
OMPI_MCA_shmem_RUNTIME_QUERY_hint=mmap
OMPI_COMM_WORLD_RANK=0
LOG_STEPS=1
PMIX_RANK=0
OMPI_FILE_LOCATION=/tmp/ompi.dd6eaccac059.0/pid.8566/0/0
NCCL_VERSION=2.4.7-1+cuda10.1
TF_FORCE_GPU_ALLOW_GROWTH=true
OMPI_MCA_orte_local_daemon_uri=3722510336.0;tcp://10.0.1.2,172.19.0.3:55665
EPOCHS_BETWEEN_EVALS=4
HOROVOD_GPU_OPERATIONS=NCCL
PWD=/root/dev/models/deploy
NUM_GPUS_PER_NODE=8
ENABLE_XLA=false
HOME=/root
PMIX_SERVER_TMPDIR=/tmp/ompi.dd6eaccac059.0/pid.8566
RUN_SCRIPT=run_resnet.sh
PMIX_PTL_MODULE=tcp,usock
IPATH_NO_BACKTRACE=1
JOB_NAME=resnet-cifar10-01_21_21_1611268802637
OMPI_MCA_rmaps_base_oversubscribe=1
OMPI_MCA_orte_launch=1
CODE_DIR=/root/dev/models/official/vision/image_classification/resnet
OMPI_MCA_orte_tmpdir_base=/tmp
LOG_DIR=/root/dev/logs
TIMESTAMP=01_21_21_1611268803649
MPI_HOST_FILE=/root/container_hosts/hosts.txt
NUM_VIRTUAL_NODES_PER_DEVICE=1
OMPI_APP_CTX_NUM_PROCS=1
OMPI_MCA_orte_output_filename=/root/dev/logs/resnet-cifar10-01_21_21_1611268802637
LOG_FILE=/dev/stderr
MODELS_DIR=/root/dev/models
OMPI_MCA_orte_app_num=0
DISABLE_VIRTUAL_NODES=true
PMIX_MCA_mca_base_component_show_load_errors=1
NUM_NODES=1
OMPI_MCA_pml=ob1
PYTHON_COMMAND=/usr/bin/python3
IN_DOCKER_CONTAINER=true
LEARNING_RATE_BATCH_SIZE=0
NUM_EPOCHS=100000
PMIX_BFROP_BUFFER_TYPE=PMIX_BFROP_BUFFER_NON_DESC
MPI_HOME=/usr/local
TERM=xterm
CUDA_PKG_VERSION=10-1=10.1.243-1
CUDA_VERSION=10.1.243
SKIP_EVAL=true
PMIX_DSTORE_ESH_BASE_PATH=/tmp/ompi.dd6eaccac059.0/pid.8566/pmix_dstor_ds12_8566
OMPI_MCA_hwloc_base_binding_policy=none
OMPI_MCA_rmaps_base_mapping_policy=node
PMIX_SERVER_URI3=3722510336.0;tcp4://127.0.0.1:49349
PMIX_SERVER_URI2=3722510336.0;tcp4://127.0.0.1:49349
NUM_STEPS=100000
OMPI_MCA_orte_hnp_uri=3722510336.0;tcp://10.0.1.2,172.19.0.3:55665
HETEROGENEOUS_VERBOSE=true
TRAIN_DIR=/root/dev/logs/resnet-cifar10-01_21_21_1611268802637
ENABLE_EAGER=true
OMPI_MCA_mpi_yield_when_idle=0
NVIDIA_DRIVER_CAPABILITIES=compute,utility
DEFAULT_NUM_GPUS_PER_NODE=8
ENABLE_CHECKPOINTS=false
DISTRIBUTION_STRATEGY=mirrored
OMPI_COMM_WORLD_LOCAL_SIZE=1
CUDA_VISIBLE_DEVICES=0,1
OMPI_COMM_WORLD_SIZE=1
SHLVL=3
PYTHONPATH=$PYTHONPATH:/root/dev/models:/root/dev/models:/root/dev/models
OMPI_NUM_APP_CTX=1
NVIDIA_REQUIRE_CUDA=cuda>=10.1 brand=tesla,driver>=396,driver<397 brand=tesla,driver>=410,driver<411 brand=tesla,driver>=418,driver<419
OMPI_MCA_pmix=^s1,s2,cray,isolated
DEFAULT_DISTRIBUTION_STRATEGY=mirrored
PMIX_SERVER_URI21=3722510336.0;tcp4://127.0.0.1:49349
SAVED_CHECKPOINT_PATH=
PMIX_DSTORE_21_BASE_PATH=/tmp/ompi.dd6eaccac059.0/pid.8566/pmix_dstor_ds21_8566
ENABLE_MONITOR_MEMORY=false
CUBLAS_VERSION=10.1.0.105-1
BATCH_SIZE=2048
PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
RUN_FILE=resnet_cifar_main.py
PMIX_SECURITY_MODE=native
OMPI_MCA_ess=^singleton
NCCL_DEBUG=INFO
PMIX_NAMESPACE=3722510337
OMPI_MCA_orte_ess_num_procs=1
NCCL_SOCKET_IFNAME=^lo,docker0,eth1
OMPI_MCA_ess_base_jobid=3722510337
OMPI_COMM_WORLD_LOCAL_RANK=0
OMPI_UNIVERSE_SIZE=2
OMPI_MCA_orte_jobfam_session_dir=/tmp/ompi.dd6eaccac059.0/pid.8566
HETEROGENEOUS_PROFILE_MAX_BATCH_SIZE=2048
DEFAULT_NUM_EPOCHS=1
PMIX_GDS_MODULE=ds21,ds12,hash
ENABLE_ELASTICITY=false
NUM_GPUS=2
OMPI_MCA_btl=^openib
_=/usr/bin/printenv
==========================================================================

2021-01-21 22:40:04.077814: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
I0121 22:40:06.428376 139942641141568 virtual_helper.py:177] Setting TF_CONFIG to {"cluster": {"worker": ["dd6eaccac059:2222"]}, "task": {"type": "worker", "index": 0}}
2021-01-21 22:40:06.428736: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-21 22:40:06.428825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-01-21 22:40:08.717928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.665GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-01-21 22:40:08.718966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:81:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.665GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-01-21 22:40:08.719011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2021-01-21 22:40:08.721542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2021-01-21 22:40:08.721591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2021-01-21 22:40:08.723643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-21 22:40:08.724045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-21 22:40:08.726305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-21 22:40:08.727637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2021-01-21 22:40:08.732042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2021-01-21 22:40:08.735410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
INFO:tensorflow:Initializing local devices since in-graph multi-worker training with `MirroredStrategy` is not supported in eager mode. TF_CONFIG will be ignored when when initializing `MirroredStrategy`.
I0121 22:40:08.736448 139942641141568 mirrored_strategy.py:306] Initializing local devices since in-graph multi-worker training with `MirroredStrategy` is not supported in eager mode. TF_CONFIG will be ignored when when initializing `MirroredStrategy`.
2021-01-21 22:40:08.739000: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-01-21 22:40:09.279047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.665GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-01-21 22:40:09.280142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:81:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.665GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-01-21 22:40:09.280188: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2021-01-21 22:40:09.280258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2021-01-21 22:40:09.280286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2021-01-21 22:40:09.280311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-01-21 22:40:09.280336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-01-21 22:40:09.280360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-01-21 22:40:09.280385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2021-01-21 22:40:09.280410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2021-01-21 22:40:09.284430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-01-21 22:40:09.284486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2021-01-21 22:42:25.635728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-01-21 22:42:25.635784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1 
2021-01-21 22:42:25.635795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N 
2021-01-21 22:42:25.635803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N 
2021-01-21 22:42:25.640076: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2021-01-21 22:42:25.640141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10097 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:03:00.0, compute capability: 7.5)
2021-01-21 22:42:25.642422: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2021-01-21 22:42:25.642467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10098 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:81:00.0, compute capability: 7.5)
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0121 22:42:25.654743 139942641141568 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')
I0121 22:42:25.699094 139942641141568 cifar_preprocessing.py:146] Sharding the dataset: input_pipeline_id=0 num_input_pipelines=1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.301603 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.303276 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.308459 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.309694 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.314698 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.319406 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.342417 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.343633 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.346208 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0121 22:42:26.347434 139942641141568 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
2021-01-21 22:42:28.591695: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-01-21 22:42:28.677508: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2095155000 Hz
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '
INFO:tensorflow:Heterogeneous training: now profiling for batch size 2
I0121 22:42:28.778854 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 2
INFO:tensorflow:Running non-virtual train step
I0121 22:42:28.848176 139931594757888 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:42:30.834331 139931041134336 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:42:32.457145 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Running non-virtual train step
I0121 22:42:36.087942 139931041134336 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:42:37.692674 139931594757888 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:42:39.331385 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
2021-01-21 22:42:46.315418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
2021-01-21 22:42:47.935580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
dd6eaccac059:8590:8737 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.1.2<0>
dd6eaccac059:8590:8737 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).

dd6eaccac059:8590:8737 [1] misc/ibvwrap.cc:63 NCCL WARN Failed to open libibverbs.so[.1]
NCCL version 2.4.7+cuda10.1
dd6eaccac059:8590:8765 [0] NCCL INFO Setting affinity for GPU 0 to ff00ff
dd6eaccac059:8590:8766 [1] NCCL INFO Setting affinity for GPU 1 to ff00ff00
dd6eaccac059:8590:8765 [0] NCCL INFO Channel 00 :    0   1
dd6eaccac059:8590:8765 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via direct shared memory
dd6eaccac059:8590:8766 [1] NCCL INFO Ring 00 : 1[1] -> 0[0] via direct shared memory
dd6eaccac059:8590:8765 [0] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled
dd6eaccac059:8590:8766 [1] NCCL INFO comm 0x7f4358006890 rank 1 nranks 2 cudaDev 1 nvmlDev 1 - Init COMPLETE
dd6eaccac059:8590:8765 [0] NCCL INFO comm 0x7f4360007d10 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE
dd6eaccac059:8590:8762 [0] NCCL INFO Launch mode Group/CGMD
I0121 22:42:50.807575 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:50.808443 139942641141568 keras_utils.py:170] TimeHistory: 22.03 seconds, 0.09 examples/second between steps 0 and 1
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
I0121 22:42:50.863925 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:50.864125 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 36.16 examples/second between steps 1 and 2
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
I0121 22:42:50.921372 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:50.921593 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 34.95 examples/second between steps 2 and 3
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
I0121 22:42:50.959145 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:50.959382 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 53.32 examples/second between steps 3 and 4
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
I0121 22:42:51.001700 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:51.001873 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 47.46 examples/second between steps 4 and 5
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
I0121 22:42:51.046115 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:51.046272 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 45.25 examples/second between steps 5 and 6
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
I0121 22:42:51.085425 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:51.085622 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 51.10 examples/second between steps 6 and 7
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
I0121 22:42:51.129247 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:51.129472 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 45.89 examples/second between steps 7 and 8
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
I0121 22:42:51.176296 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:51.176479 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 42.81 examples/second between steps 8 and 9
Input shape = [1 32 32 3]
Input shape = [1 32 32 3]
I0121 22:42:51.230373 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2
I0121 22:42:51.230562 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 37.16 examples/second between steps 9 and 10
INFO:tensorflow:Heterogeneous training: now profiling for batch size 4
I0121 22:42:51.230931 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 4
INFO:tensorflow:Running non-virtual train step
I0121 22:42:51.260149 139939734550272 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:42:53.080979 139941778269952 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:42:54.716202 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:01.971266 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:01.971873 139942641141568 keras_utils.py:170] TimeHistory: 10.74 seconds, 0.37 examples/second between steps 10 and 11
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:02.033799 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:02.033987 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 64.71 examples/second between steps 11 and 12
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:02.107118 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:02.107295 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 54.72 examples/second between steps 12 and 13
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:02.170292 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:02.170451 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 63.55 examples/second between steps 13 and 14
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:02.242021 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:02.242186 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 55.92 examples/second between steps 14 and 15
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:02.281915 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:02.282051 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 100.78 examples/second between steps 15 and 16
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:02.328645 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:02.328883 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 85.80 examples/second between steps 16 and 17
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:02.375249 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:02.375385 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 86.59 examples/second between steps 17 and 18
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:02.422521 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:02.422700 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 84.94 examples/second between steps 18 and 19
Input shape = [2 32 32 3]
Input shape = [2 32 32 3]
I0121 22:43:02.462442 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 4
I0121 22:43:02.462574 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 100.87 examples/second between steps 19 and 20
INFO:tensorflow:Heterogeneous training: now profiling for batch size 8
I0121 22:43:02.462779 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 8
INFO:tensorflow:Running non-virtual train step
I0121 22:43:02.476467 139940162447104 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:43:04.308999 139940120499968 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:43:05.901426 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:12.785192 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:12.785549 139942641141568 keras_utils.py:170] TimeHistory: 10.32 seconds, 0.77 examples/second between steps 20 and 21
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:12.865468 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:12.865674 139942641141568 keras_utils.py:170] TimeHistory: 0.08 seconds, 100.23 examples/second between steps 21 and 22
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:12.930043 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:12.930218 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 124.40 examples/second between steps 22 and 23
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:12.997469 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:12.997659 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 119.02 examples/second between steps 23 and 24
Epoch 1/100000
24/24 - 44s - loss: 3689.5483 - sparse_categorical_accuracy: 0.0652
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:13.057737 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:13.057905 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 178.38 examples/second between steps 24 and 25
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:13.104780 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:13.105059 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 170.43 examples/second between steps 25 and 26
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:13.154726 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:13.154968 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 161.44 examples/second between steps 26 and 27
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:13.203906 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:13.204066 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 163.96 examples/second between steps 27 and 28
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:13.254255 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:13.254400 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 159.53 examples/second between steps 28 and 29
Input shape = [4 32 32 3]
Input shape = [4 32 32 3]
I0121 22:43:13.300059 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 8
I0121 22:43:13.300208 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 175.41 examples/second between steps 29 and 30
INFO:tensorflow:Heterogeneous training: now profiling for batch size 16
I0121 22:43:13.300464 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 16
INFO:tensorflow:Running non-virtual train step
I0121 22:43:13.315158 139939994658560 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:43:15.497821 139939952711424 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:43:17.169447 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.223826 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.224624 139942641141568 keras_utils.py:170] TimeHistory: 10.92 seconds, 1.46 examples/second between steps 30 and 31
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.298624 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.298812 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 216.60 examples/second between steps 31 and 32
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.354811 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.354971 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 285.98 examples/second between steps 32 and 33
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.428946 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.429233 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 216.05 examples/second between steps 33 and 34
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.491537 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.491812 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 256.77 examples/second between steps 34 and 35
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.531791 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.532039 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 400.57 examples/second between steps 35 and 36
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.578923 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.579098 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 342.52 examples/second between steps 36 and 37
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.632712 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.632863 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 298.98 examples/second between steps 37 and 38
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.670467 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.670678 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 425.25 examples/second between steps 38 and 39
Input shape = [8 32 32 3]
Input shape = [8 32 32 3]
I0121 22:43:24.711051 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 16
I0121 22:43:24.711245 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 397.07 examples/second between steps 39 and 40
INFO:tensorflow:Heterogeneous training: now profiling for batch size 32
I0121 22:43:24.711574 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 32
INFO:tensorflow:Running non-virtual train step
I0121 22:43:24.734392 139939899488000 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:43:26.508287 139939818477312 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:43:28.141899 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:35.602270 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:35.602670 139942641141568 keras_utils.py:170] TimeHistory: 10.89 seconds, 2.94 examples/second between steps 40 and 41
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:35.690047 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:35.690243 139942641141568 keras_utils.py:170] TimeHistory: 0.09 seconds, 366.62 examples/second between steps 41 and 42
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:35.747039 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:35.747255 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 563.05 examples/second between steps 42 and 43
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:35.822778 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:35.822970 139942641141568 keras_utils.py:170] TimeHistory: 0.08 seconds, 424.11 examples/second between steps 43 and 44
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:35.869763 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:35.870018 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 683.62 examples/second between steps 44 and 45
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:35.914969 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:35.915109 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 714.70 examples/second between steps 45 and 46
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:35.952092 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:35.952239 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 865.79 examples/second between steps 46 and 47
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:35.989636 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:35.989825 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 856.44 examples/second between steps 47 and 48
Epoch 2/100000
24/24 - 23s - loss: 5281.0903 - sparse_categorical_accuracy: 0.1207
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:36.046135 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:36.046359 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 751.23 examples/second between steps 48 and 49
Input shape = [16 32 32 3]
Input shape = [16 32 32 3]
I0121 22:43:36.088100 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 32
I0121 22:43:36.088306 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 767.12 examples/second between steps 49 and 50
INFO:tensorflow:Heterogeneous training: now profiling for batch size 64
I0121 22:43:36.088601 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 64
INFO:tensorflow:Running non-virtual train step
I0121 22:43:36.106905 139939764238080 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:43:37.830092 139939755845376 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:43:39.476708 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:46.518489 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:46.518836 139942641141568 keras_utils.py:170] TimeHistory: 10.43 seconds, 6.14 examples/second between steps 50 and 51
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:46.592174 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:46.592382 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 873.44 examples/second between steps 51 and 52
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:46.748661 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:46.748825 139942641141568 keras_utils.py:170] TimeHistory: 0.16 seconds, 409.73 examples/second between steps 52 and 53
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:46.811981 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:46.812133 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 1017.33 examples/second between steps 53 and 54
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:46.863577 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:46.863756 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 1245.58 examples/second between steps 54 and 55
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:46.916460 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:46.916619 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 1215.87 examples/second between steps 55 and 56
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:46.959980 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:46.960172 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 1475.75 examples/second between steps 56 and 57
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:47.002709 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:47.002884 139942641141568 keras_utils.py:170] TimeHistory: 0.04 seconds, 1507.99 examples/second between steps 57 and 58
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:47.055703 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:47.055898 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 1212.74 examples/second between steps 58 and 59
Input shape = [32 32 32 3]
Input shape = [32 32 32 3]
I0121 22:43:47.104002 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 64
I0121 22:43:47.104189 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 1330.61 examples/second between steps 59 and 60
INFO:tensorflow:Heterogeneous training: now profiling for batch size 128
I0121 22:43:47.104405 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 128
INFO:tensorflow:Running non-virtual train step
I0121 22:43:47.122305 139930277758720 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:43:48.947383 139930269366016 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:43:50.587558 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.170697 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.171060 139942641141568 keras_utils.py:170] TimeHistory: 11.07 seconds, 11.57 examples/second between steps 60 and 61
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.251431 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.251608 139942641141568 keras_utils.py:170] TimeHistory: 0.08 seconds, 1593.92 examples/second between steps 61 and 62
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.317759 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.317916 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 1937.46 examples/second between steps 62 and 63
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.380887 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.381056 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 2034.10 examples/second between steps 63 and 64
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.429720 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.429888 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 2632.58 examples/second between steps 64 and 65
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.479510 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.479848 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 2576.64 examples/second between steps 65 and 66
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.527442 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.527726 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 2692.45 examples/second between steps 66 and 67
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.577238 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.577439 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 2588.17 examples/second between steps 67 and 68
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.637903 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.638268 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 2113.02 examples/second between steps 68 and 69
Input shape = [64 32 32 3]
Input shape = [64 32 32 3]
I0121 22:43:58.699520 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 128
I0121 22:43:58.699784 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 2090.91 examples/second between steps 69 and 70
INFO:tensorflow:Heterogeneous training: now profiling for batch size 256
I0121 22:43:58.700043 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 256
INFO:tensorflow:Running non-virtual train step
I0121 22:43:58.714585 139930260973312 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:44:00.477862 139930252580608 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:44:02.171319 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.220726 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.221159 139942641141568 keras_utils.py:170] TimeHistory: 10.52 seconds, 24.33 examples/second between steps 70 and 71
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.306734 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.306929 139942641141568 keras_utils.py:170] TimeHistory: 0.09 seconds, 2996.26 examples/second between steps 71 and 72
Epoch 3/100000
24/24 - 33s - loss: 4085.4407 - sparse_categorical_accuracy: 0.0946
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.397540 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.397721 139942641141568 keras_utils.py:170] TimeHistory: 0.08 seconds, 3334.14 examples/second between steps 72 and 73
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.462043 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.462228 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 3980.82 examples/second between steps 73 and 74
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.520673 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.520884 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 4378.85 examples/second between steps 74 and 75
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.572590 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.572898 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 4944.13 examples/second between steps 75 and 76
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.627026 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.627280 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 4740.85 examples/second between steps 76 and 77
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.687066 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.687331 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 4281.68 examples/second between steps 77 and 78
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.741689 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.741913 139942641141568 keras_utils.py:170] TimeHistory: 0.05 seconds, 4713.67 examples/second between steps 78 and 79
Input shape = [128 32 32 3]
Input shape = [128 32 32 3]
I0121 22:44:09.803807 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 256
I0121 22:44:09.804078 139942641141568 keras_utils.py:170] TimeHistory: 0.06 seconds, 4132.05 examples/second between steps 79 and 80
INFO:tensorflow:Heterogeneous training: now profiling for batch size 512
I0121 22:44:09.804372 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 512
INFO:tensorflow:Running non-virtual train step
I0121 22:44:09.818572 139929128531712 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:44:11.489563 139929120139008 training.py:892] Running non-virtual train step
INFO:tensorflow:batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
I0121 22:44:13.077489 139942641141568 cross_device_ops.py:847] batch_all_reduce: 176 all-reduces with algorithm = nccl, num_packs = 1
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:20.292058 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:20.292655 139942641141568 keras_utils.py:170] TimeHistory: 10.49 seconds, 48.82 examples/second between steps 80 and 81
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:20.407169 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:20.407351 139942641141568 keras_utils.py:170] TimeHistory: 0.11 seconds, 4475.04 examples/second between steps 81 and 82
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:20.481712 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:20.481885 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 6888.81 examples/second between steps 82 and 83
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:20.562042 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:20.562309 139942641141568 keras_utils.py:170] TimeHistory: 0.08 seconds, 6382.51 examples/second between steps 83 and 84
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:20.636702 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:20.636890 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 6882.83 examples/second between steps 84 and 85
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:20.717726 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:20.717890 139942641141568 keras_utils.py:170] TimeHistory: 0.08 seconds, 6335.88 examples/second between steps 85 and 86
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:20.790853 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:20.791029 139942641141568 keras_utils.py:170] TimeHistory: 0.07 seconds, 7019.92 examples/second between steps 86 and 87
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:20.888191 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:20.888420 139942641141568 keras_utils.py:170] TimeHistory: 0.10 seconds, 5269.42 examples/second between steps 87 and 88
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:20.964972 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:20.965303 139942641141568 keras_utils.py:170] TimeHistory: 0.08 seconds, 6682.59 examples/second between steps 88 and 89
Input shape = [256 32 32 3]
Input shape = [256 32 32 3]
I0121 22:44:21.051738 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 512
I0121 22:44:21.052030 139942641141568 keras_utils.py:170] TimeHistory: 0.09 seconds, 5922.41 examples/second between steps 89 and 90
INFO:tensorflow:Heterogeneous training: now profiling for batch size 1024
I0121 22:44:21.052428 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 1024
INFO:tensorflow:Running non-virtual train step
I0121 22:44:21.074942 139929111746304 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:44:23.390377 139928994313984 training.py:892] Running non-virtual train step
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:32.265387 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:32.265616 139942641141568 keras_utils.py:170] TimeHistory: 11.21 seconds, 91.32 examples/second between steps 90 and 91
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:32.390218 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:32.390427 139942641141568 keras_utils.py:170] TimeHistory: 0.12 seconds, 8217.12 examples/second between steps 91 and 92
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:32.514107 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:32.514319 139942641141568 keras_utils.py:170] TimeHistory: 0.12 seconds, 8278.48 examples/second between steps 92 and 93
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:32.640569 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:32.640873 139942641141568 keras_utils.py:170] TimeHistory: 0.13 seconds, 8106.10 examples/second between steps 93 and 94
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:32.766781 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:32.767083 139942641141568 keras_utils.py:170] TimeHistory: 0.13 seconds, 8133.81 examples/second between steps 94 and 95
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:32.892533 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:32.892761 139942641141568 keras_utils.py:170] TimeHistory: 0.13 seconds, 8164.86 examples/second between steps 95 and 96
Epoch 4/100000
24/24 - 24s - loss: 2963.4243 - sparse_categorical_accuracy: 0.0989
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:33.026706 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:33.026914 139942641141568 keras_utils.py:170] TimeHistory: 0.12 seconds, 8312.40 examples/second between steps 96 and 97
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:33.150982 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:33.151277 139942641141568 keras_utils.py:170] TimeHistory: 0.12 seconds, 8250.05 examples/second between steps 97 and 98
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:33.276026 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:33.276222 139942641141568 keras_utils.py:170] TimeHistory: 0.12 seconds, 8217.23 examples/second between steps 98 and 99
Input shape = [512 32 32 3]
Input shape = [512 32 32 3]
I0121 22:44:33.402719 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 1024
I0121 22:44:33.402957 139942641141568 keras_utils.py:170] TimeHistory: 0.13 seconds, 8094.32 examples/second between steps 99 and 100
INFO:tensorflow:Heterogeneous training: now profiling for batch size 2048
I0121 22:44:33.403276 139942641141568 training.py:1264] Heterogeneous training: now profiling for batch size 2048
INFO:tensorflow:Running non-virtual train step
I0121 22:44:33.418626 139928985921280 training.py:892] Running non-virtual train step
INFO:tensorflow:Running non-virtual train step
I0121 22:44:35.226091 139928977528576 training.py:892] Running non-virtual train step
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:43.318630 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:43.319031 139942641141568 keras_utils.py:170] TimeHistory: 9.92 seconds, 206.54 examples/second between steps 100 and 101
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:43.542734 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:43.543055 139942641141568 keras_utils.py:170] TimeHistory: 0.22 seconds, 9160.27 examples/second between steps 101 and 102
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:43.768905 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:43.769210 139942641141568 keras_utils.py:170] TimeHistory: 0.23 seconds, 9068.32 examples/second between steps 102 and 103
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:43.994578 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:43.994820 139942641141568 keras_utils.py:170] TimeHistory: 0.23 seconds, 9089.68 examples/second between steps 103 and 104
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:44.222426 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:44.222649 139942641141568 keras_utils.py:170] TimeHistory: 0.23 seconds, 9000.93 examples/second between steps 104 and 105
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:44.447186 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:44.447437 139942641141568 keras_utils.py:170] TimeHistory: 0.22 seconds, 9122.61 examples/second between steps 105 and 106
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:44.672714 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:44.672946 139942641141568 keras_utils.py:170] TimeHistory: 0.23 seconds, 9094.30 examples/second between steps 106 and 107
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:44.895980 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:44.896176 139942641141568 keras_utils.py:170] TimeHistory: 0.22 seconds, 9187.19 examples/second between steps 107 and 108
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:45.116623 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:45.116849 139942641141568 keras_utils.py:170] TimeHistory: 0.22 seconds, 9290.52 examples/second between steps 108 and 109
Input shape = [1024 32 32 3]
Input shape = [1024 32 32 3]
I0121 22:44:45.339460 139942641141568 keras_utils.py:155] TimeHistory updating batch size to 2048
I0121 22:44:45.339702 139942641141568 keras_utils.py:170] TimeHistory: 0.22 seconds, 9202.35 examples/second between steps 109 and 110
INFO:tensorflow:Heterogeneous training profile complete
I0121 22:44:45.340014 139942641141568 training.py:1256] Heterogeneous training profile complete
Epoch 5/100000
24/24 - 12s - loss: 2359.4197 - sparse_categorical_accuracy: 0.1016
I0121 22:44:45.342447 139942641141568 keras_utils.py:134] Wrote to /root/dev/logs/resnet-cifar10-01_21_21_1611268802637/heterogeneous_profile.txt
{'loss': 2359.419677734375, 'training_accuracy_top_1': 0.1015625, 'step_timestamp_log': ['BatchTimestamp<batch_index: 0, timestamp: 1611268948.7787821>', 'BatchTimestamp<batch_index: 1, timestamp: 1611268970.808367>', 'BatchTimestamp<batch_index: 2, timestamp: 1611268970.864091>', 'BatchTimestamp<batch_index: 3, timestamp: 1611268970.921556>', 'BatchTimestamp<batch_index: 4, timestamp: 1611268970.9593413>', 'BatchTimestamp<batch_index: 5, timestamp: 1611268971.0018454>', 'BatchTimestamp<batch_index: 6, timestamp: 1611268971.046246>', 'BatchTimestamp<batch_index: 7, timestamp: 1611268971.0855856>', 'BatchTimestamp<batch_index: 8, timestamp: 1611268971.12943>', 'BatchTimestamp<batch_index: 9, timestamp: 1611268971.1764417>', 'BatchTimestamp<batch_index: 10, timestamp: 1611268971.230526>', 'BatchTimestamp<batch_index: 11, timestamp: 1611268981.9718215>', 'BatchTimestamp<batch_index: 12, timestamp: 1611268982.0339592>', 'BatchTimestamp<batch_index: 13, timestamp: 1611268982.1072657>', 'BatchTimestamp<batch_index: 14, timestamp: 1611268982.170423>', 'BatchTimestamp<batch_index: 15, timestamp: 1611268982.2421618>', 'BatchTimestamp<batch_index: 16, timestamp: 1611268982.2820275>', 'BatchTimestamp<batch_index: 17, timestamp: 1611268982.3288457>', 'BatchTimestamp<batch_index: 18, timestamp: 1611268982.375361>', 'BatchTimestamp<batch_index: 19, timestamp: 1611268982.4226742>', 'BatchTimestamp<batch_index: 20, timestamp: 1611268982.462551>', 'BatchTimestamp<batch_index: 21, timestamp: 1611268992.7855027>', 'BatchTimestamp<batch_index: 22, timestamp: 1611268992.8656418>', 'BatchTimestamp<batch_index: 23, timestamp: 1611268992.9301863>', 'BatchTimestamp<batch_index: 24, timestamp: 1611268992.997627>', 'BatchTimestamp<batch_index: 25, timestamp: 1611268993.0578802>', 'BatchTimestamp<batch_index: 26, timestamp: 1611268993.1049929>', 'BatchTimestamp<batch_index: 27, timestamp: 1611268993.1549253>', 'BatchTimestamp<batch_index: 28, timestamp: 1611268993.204039>', 'BatchTimestamp<batch_index: 29, timestamp: 1611268993.254375>', 'BatchTimestamp<batch_index: 30, timestamp: 1611268993.3001812>', 'BatchTimestamp<batch_index: 31, timestamp: 1611269004.224551>', 'BatchTimestamp<batch_index: 32, timestamp: 1611269004.2987797>', 'BatchTimestamp<batch_index: 33, timestamp: 1611269004.3549428>', 'BatchTimestamp<batch_index: 34, timestamp: 1611269004.429203>', 'BatchTimestamp<batch_index: 35, timestamp: 1611269004.4917393>', 'BatchTimestamp<batch_index: 36, timestamp: 1611269004.5320013>', 'BatchTimestamp<batch_index: 37, timestamp: 1611269004.579066>', 'BatchTimestamp<batch_index: 38, timestamp: 1611269004.6328394>', 'BatchTimestamp<batch_index: 39, timestamp: 1611269004.6706393>', 'BatchTimestamp<batch_index: 40, timestamp: 1611269004.711208>', 'BatchTimestamp<batch_index: 41, timestamp: 1611269015.6025996>', 'BatchTimestamp<batch_index: 42, timestamp: 1611269015.6902177>', 'BatchTimestamp<batch_index: 43, timestamp: 1611269015.7472208>', 'BatchTimestamp<batch_index: 44, timestamp: 1611269015.8229425>', 'BatchTimestamp<batch_index: 45, timestamp: 1611269015.8699737>', 'BatchTimestamp<batch_index: 46, timestamp: 1611269015.9150794>', 'BatchTimestamp<batch_index: 47, timestamp: 1611269015.9522166>', 'BatchTimestamp<batch_index: 48, timestamp: 1611269015.9897904>', 'BatchTimestamp<batch_index: 49, timestamp: 1611269016.0463145>', 'BatchTimestamp<batch_index: 50, timestamp: 1611269016.0882678>', 'BatchTimestamp<batch_index: 51, timestamp: 1611269026.5187979>', 'BatchTimestamp<batch_index: 52, timestamp: 1611269026.5923417>', 'BatchTimestamp<batch_index: 53, timestamp: 1611269026.7487943>', 'BatchTimestamp<batch_index: 54, timestamp: 1611269026.8121018>', 'BatchTimestamp<batch_index: 55, timestamp: 1611269026.8637242>', 'BatchTimestamp<batch_index: 56, timestamp: 1611269026.9165943>', 'BatchTimestamp<batch_index: 57, timestamp: 1611269026.9601374>', 'BatchTimestamp<batch_index: 58, timestamp: 1611269027.0028517>', 'BatchTimestamp<batch_index: 59, timestamp: 1611269027.0558722>', 'BatchTimestamp<batch_index: 60, timestamp: 1611269027.1041555>', 'BatchTimestamp<batch_index: 61, timestamp: 1611269038.1710186>', 'BatchTimestamp<batch_index: 62, timestamp: 1611269038.2515774>', 'BatchTimestamp<batch_index: 63, timestamp: 1611269038.317887>', 'BatchTimestamp<batch_index: 64, timestamp: 1611269038.3810263>', 'BatchTimestamp<batch_index: 65, timestamp: 1611269038.4298615>', 'BatchTimestamp<batch_index: 66, timestamp: 1611269038.4797952>', 'BatchTimestamp<batch_index: 67, timestamp: 1611269038.527689>', 'BatchTimestamp<batch_index: 68, timestamp: 1611269038.5774114>', 'BatchTimestamp<batch_index: 69, timestamp: 1611269038.6382265>', 'BatchTimestamp<batch_index: 70, timestamp: 1611269038.6997473>', 'BatchTimestamp<batch_index: 71, timestamp: 1611269049.2210913>', 'BatchTimestamp<batch_index: 72, timestamp: 1611269049.306896>', 'BatchTimestamp<batch_index: 73, timestamp: 1611269049.3976922>', 'BatchTimestamp<batch_index: 74, timestamp: 1611269049.4622004>', 'BatchTimestamp<batch_index: 75, timestamp: 1611269049.5208552>', 'BatchTimestamp<batch_index: 76, timestamp: 1611269049.572844>', 'BatchTimestamp<batch_index: 77, timestamp: 1611269049.6272433>', 'BatchTimestamp<batch_index: 78, timestamp: 1611269049.6873035>', 'BatchTimestamp<batch_index: 79, timestamp: 1611269049.7418706>', 'BatchTimestamp<batch_index: 80, timestamp: 1611269049.8040369>', 'BatchTimestamp<batch_index: 81, timestamp: 1611269060.2926116>', 'BatchTimestamp<batch_index: 82, timestamp: 1611269060.4073167>', 'BatchTimestamp<batch_index: 83, timestamp: 1611269060.481857>', 'BatchTimestamp<batch_index: 84, timestamp: 1611269060.562282>', 'BatchTimestamp<batch_index: 85, timestamp: 1611269060.6368625>', 'BatchTimestamp<batch_index: 86, timestamp: 1611269060.7178667>', 'BatchTimestamp<batch_index: 87, timestamp: 1611269060.7909892>', 'BatchTimestamp<batch_index: 88, timestamp: 1611269060.888383>', 'BatchTimestamp<batch_index: 89, timestamp: 1611269060.9652643>', 'BatchTimestamp<batch_index: 90, timestamp: 1611269061.0519857>', 'BatchTimestamp<batch_index: 91, timestamp: 1611269072.2655861>', 'BatchTimestamp<batch_index: 92, timestamp: 1611269072.3903995>', 'BatchTimestamp<batch_index: 93, timestamp: 1611269072.5142903>', 'BatchTimestamp<batch_index: 94, timestamp: 1611269072.6408327>', 'BatchTimestamp<batch_index: 95, timestamp: 1611269072.7670503>', 'BatchTimestamp<batch_index: 96, timestamp: 1611269072.8927321>', 'BatchTimestamp<batch_index: 97, timestamp: 1611269073.0268888>', 'BatchTimestamp<batch_index: 98, timestamp: 1611269073.1512308>', 'BatchTimestamp<batch_index: 99, timestamp: 1611269073.2761908>', 'BatchTimestamp<batch_index: 100, timestamp: 1611269073.4029188>', 'BatchTimestamp<batch_index: 101, timestamp: 1611269083.318968>', 'BatchTimestamp<batch_index: 102, timestamp: 1611269083.543008>', 'BatchTimestamp<batch_index: 103, timestamp: 1611269083.7691667>', 'BatchTimestamp<batch_index: 104, timestamp: 1611269083.9947777>', 'BatchTimestamp<batch_index: 105, timestamp: 1611269084.2226102>', 'BatchTimestamp<batch_index: 106, timestamp: 1611269084.447371>', 'BatchTimestamp<batch_index: 107, timestamp: 1611269084.6729045>', 'BatchTimestamp<batch_index: 108, timestamp: 1611269084.896143>', 'BatchTimestamp<batch_index: 109, timestamp: 1611269085.1168091>', 'BatchTimestamp<batch_index: 110, timestamp: 1611269085.3396592>'], 'train_finish_time': 1611269085.3417795, 'avg_exp_per_second': 1650.2618839543948}
